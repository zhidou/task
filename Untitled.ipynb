{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = unpickle('data_batch_2')\n",
    "data = data[b'data']\n",
    "data = np.reshape(data, [-1, 32, 32, 3], order='F')\n",
    "data = data.transpose([0, 2, 1, 3])\n",
    "data = np.reshape(data, [-1, 32, 32, 3], order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80446323c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[0:20]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input parameter\n",
    "batch_size, hight, width, color_channel = data.shape\n",
    "n_input = hight * width * color_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "\n",
    "# for global contrast normalization\n",
    "def gcn(x, s=1, l=0, e=10**(-8)):\n",
    "#     transpose x(NHWC)->x(CHWN)\n",
    "    [N, H, W, C] = x.shape\n",
    "    x = x.transpose([3,1,2,0])\n",
    "    mean = (np.ones([H, W, N]) * (np.ones([W, N]) * np.mean(a=x, axis=(0,1,2))))\n",
    "    div = np.sqrt(l + np.sum(a=np.square(x - mean), axis=(0,1,2))/(C * W * H))\n",
    "#     implement max(e, xi) elementwise in tensor\n",
    "    div[div < e] = e\n",
    "    ret = (x - mean) / (np.ones([H, W, N]) * (np.ones([W, N]) * div))\n",
    "#     transpose back to (NHWC)\n",
    "    return ret.transpose([3,1,2,0])\n",
    "\n",
    "\n",
    "# zca whitening\n",
    "def zca(x, e=0.1):\n",
    "    x_white = np.reshape(x, (-1, x.shape[0]), 'C')\n",
    "    [U, S, V] = np.linalg.svd(np.dot(x_white, x_white.transpose()) / x_white.shape[0])\n",
    "    x_white =np.dot(U, np.dot(np.diag(1 / np.sqrt(S + e)), np.dot(U.transpose(), x_white)))\n",
    "    return np.reshape(x_white, x.shape, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, padding, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding = padding)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# extract patches from feature maps\n",
    "# input shape N, H, W, C\n",
    "# output shape N, H, W, K, C\n",
    "def extract_patches(x, padding, ksize=2, stride=2):\n",
    "    temp = tf.extract_image_patches(images=x, ksizes=[1, ksize, ksize, 1], strides=[1, stride, stride, 1], rates=[1,1,1,1], padding=padding)\n",
    "    [N, H, W, C] = temp.get_shape().as_list()\n",
    "    C = x.get_shape().as_list()[-1]\n",
    "#     reshape to N,H,W,K,C\n",
    "    temp = tf.reshape(temp, [N, H, W, ksize*ksize, C])\n",
    "    return temp\n",
    "\n",
    "# compute the frequency of element in each patch\n",
    "# input extracted patches tensor in shape N, H, W, K, C\n",
    "# output frequency tensor in shape N, H, W, K, C\n",
    "def majority_frequency(temp):\n",
    "    [N, H, W, K, C] = temp.get_shape().as_list()\n",
    "    temp = tf.to_int32(tf.round(temp))\n",
    "    \n",
    "#     build one hot vector\n",
    "    temp = tf.transpose(temp, [0,1,2,4,3])\n",
    "    one_hot = tf.one_hot(indices=temp, depth=tf.reduce_max(temp) + 1, dtype=tf.float32)\n",
    "#     the dimension is bathch, row, col, lay, one hot\n",
    "#     the order tensorflow takes, when doiong transpose, it will from the most right to most left\n",
    "    one_hot = tf.reduce_sum(one_hot, axis=4)\n",
    "    temp = tf.transpose(temp, [0, 3, 1, 2, 4])\n",
    "    temp = tf.reshape(temp, [-1,1])\n",
    "    one_hot = tf.transpose(one_hot, [0,3,1,2,4])\n",
    "#     one_hot = tf.reshape(one_hot, [N*H*W*C, -1])\n",
    "    one_hot = tf.reshape(one_hot, [-1, K])\n",
    "    \n",
    "    \n",
    "    index = tf.constant(np.array([range(temp.get_shape().as_list()[0])])/ K, dtype=tf.int32)\n",
    "    temp = tf.concat((tf.transpose(index), temp), axis=1)\n",
    "    \n",
    "#     to get the percentage\n",
    "    temp = tf.gather_nd(one_hot, temp)\n",
    "    temp = tf.reshape(temp, [-1, C, H, W, K])\n",
    "#     finally we change it back to N,H,W,K,C\n",
    "    temp = tf.transpose(temp, [0, 2, 3, 4, 1])\n",
    "    \n",
    "    return temp\n",
    "\n",
    "# compute weight based on frequency tensor\n",
    "# fun could be tf.reduce_max, tf.reduce_sum, reduce_size(in str)\n",
    "# output in shape N, H, W, K, C\n",
    "def compute_weight(w, fun):\n",
    "    if isinstance(fun, str): deno = w.get_shape().as_list()[3]\n",
    "    else: deno = fun(w, axis=3, keep_dims=True)\n",
    "    temp = tf.divide(w, deno)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling funtions\n",
    "\n",
    "# MaxPool\n",
    "def max_pool(p):\n",
    "    return tf.reduce_max(p, axis=3)\n",
    "\n",
    "# majority pooling\n",
    "# input frequency tensor\n",
    "# output majority pooling\n",
    "def majority_pool(p, f):\n",
    "    btemp = tf.reduce_max(f , axis=[3], keep_dims=True)\n",
    "#     get the index of the majority element\n",
    "    temp = tf.equal(f, btemp)\n",
    "    temp = tf.to_float(temp)\n",
    "#     use the largest frequency to represent each window\n",
    "    btemp = tf.squeeze(btemp, squeeze_dims=3)\n",
    "#     compute mean of the elements that have same round value in each window\n",
    "    temp = tf.divide(tf.reduce_sum(tf.multiply(p, temp), axis=[3]), btemp)\n",
    "#     when the largest frequency is 1, then we just the max value in p as the result, else use the mean of the of elements\n",
    "#     having the same round value, as the result.\n",
    "    temp = tf.where(tf.equal(btemp, 1), \n",
    "                    tf.reduce_max(p, axis=[3]), temp)\n",
    "    return temp\n",
    "\n",
    "# pcaPool\n",
    "# if m == 1, then consider each window as an unique instances, and each window have their own pca encoder\n",
    "# if m != 1, then all windows fetch from the same feature map share one pca encoder\n",
    "def pca_pool(temp, m = 1):\n",
    "    [N, H, W, K, C] = temp.get_shape().as_list()\n",
    "    if m == 1:\n",
    "        temp = tf.transpose(temp, [0,1,2,4,3])\n",
    "        temp = tf.reshape(temp, [-1, K, 1])\n",
    "    else:\n",
    "        temp = tf.transpose(temp, [0,4,3,1,2])\n",
    "        temp = tf.reshape(temp, [-1, K, H*W])\n",
    "#     compute for svd\n",
    "    [s, u, v] = tf.svd(tf.matmul(temp, tf.transpose(temp, [0,2,1])), compute_uv=True)\n",
    "#     use mark to remove Eigenvector except for the first one, which is the main component\n",
    "    temp_mark = np.zeros([K,K])\n",
    "    temp_mark[:,0] = 1\n",
    "    mark = tf.constant(temp_mark, dtype=tf.float32)\n",
    "    \n",
    "#     after reduce_sum actually it has been transposed automatically\n",
    "    u = tf.reduce_sum(tf.multiply(u, mark), axis=2)\n",
    "    u = tf.reshape(u, [-1, 1, K])\n",
    "    \n",
    "    temp = tf.matmul(u, temp)/np.sqrt(K)\n",
    "    if m == 1: temp = tf.reshape(temp, [-1, H, W, C])\n",
    "    else: \n",
    "        temp = tf.reshape(temp, [-1, C, H, W])\n",
    "        temp = tf.transpose(temp, [0, 2, 3, 1])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weithed pooling functions\n",
    "\n",
    "# weight before maxpool p:= patches, w:= weights\n",
    "def weight_pool(p, f, reduce_fun, pool_fun):\n",
    "    temp = tf.multiply(p, compute_weight(f, reduce_fun))\n",
    "    if pool_fun is majority_pool:\n",
    "        temp = pool_fun(temp, majority_frequency(temp))\n",
    "    else: temp = pool_fun(temp)\n",
    "    return temp\n",
    "\n",
    "# maxpool before weight\n",
    "def pool_weight(p, f, reduce_fun, pool_fun):\n",
    "#     for now both p and w are in the shape of N,H,W,K,C\n",
    "    [N, H, W, K, C] = p.get_shape().as_list()\n",
    "    w = compute_weight(f, reduce_fun)\n",
    "    if pool_fun is majority_pool:\n",
    "        p = pool_fun(p, f)\n",
    "        w = tf.reduce_max(w, axis=3)\n",
    "    else:\n",
    "#     argmax in the shape of N, H, W, C\n",
    "        argmax = tf.argmax(p, axis=3)\n",
    "        p = pool_fun(p)\n",
    "#     move C before H\n",
    "        argmax = tf.transpose(argmax, [0, 3, 1, 2])\n",
    "        w = tf.transpose(w, [0, 4, 1, 2, 3])\n",
    "#     flatten argmax and w\n",
    "        argmax = tf.reshape(argmax, [N*H*W*C, 1])\n",
    "        w = tf.reshape(w, [N*H*W*C, K])\n",
    "#     create index helper\n",
    "        index = tf.constant(np.array([range(argmax.get_shape().as_list()[0])]), dtype=tf.int64)\n",
    "        argmax = tf.concat((tf.transpose(index), argmax), axis=1)\n",
    "#     get the corresponding weight of the max\n",
    "        w = tf.gather_nd(w, argmax)\n",
    "        w = tf.reshape(w, [N, C, H, W])\n",
    "        w = tf.transpose(w, [0, 2, 3, 1])\n",
    "    \n",
    "    return tf.multiply(p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the gcn function\n",
    "test_data = data[0,:,:,:]\n",
    "mean = np.mean(test_data)\n",
    "test_gcn = (test_data - mean) / max(10**(-8), np.sqrt(np.sum(np.square(test_data - mean))/(hight * width * color_channel)))\n",
    "test_gcn1 = gcn(data[0:2])\n",
    "np.max(test_gcn - test_gcn1[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = np.array([range(1, 33)])\n",
    "tt = np.reshape(tt, [1,4,4,2], order='F')\n",
    "tt = np.transpose(tt, [0, 2, 1, 3])\n",
    "tt = np.reshape(tt, [1,4,4,2], order='C')\n",
    "tt[0,0,3,0] = 3\n",
    "tt[0,2,0,0] = 13\n",
    "tt[0,2,1,0] = 13\n",
    "tt[0,2,3,0] = 11\n",
    "tt[0,3,2,0] = 11\n",
    "tt[0,3,3,0] = 11\n",
    "tt[0,0,0,1] = 18\n",
    "tt[0,1,0,1] = 18\n",
    "tt[0,1,1,1] = 18\n",
    "tt[0,0,2,1] = 23\n",
    "tt[0,0,3,1] = 23\n",
    "tt[0,2,0,1] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test pooling functions\n",
    "x = tf.constant(tt, dtype=tf.float32)\n",
    "\n",
    "p = extract_patches(x, \"VALID\", 2, 2)\n",
    "f = majority_frequency(p)\n",
    "r0 = max_pool(p)\n",
    "r1 = majority_pool(p, f)\n",
    "r2 = weight_pool(p, f, tf.reduce_max, majority_pool)\n",
    "r3 = pool_weight(p, f, tf.reduce_max, majority_pool)\n",
    "r4 = weight_pool(p, f, tf.reduce_max, max_pool)\n",
    "r5 = pool_weight(p, f, tf.reduce_max, max_pool)\n",
    "# temp = max_weight(p, f, tf.reduce_max)\n",
    "\n",
    "# temp = tf.nn.max_pool(x, ksize=[1,2,2,1],padding='VALID',strides=[1,2,2,1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ret0 = sess.run(r0)\n",
    "    ret1 = sess.run(r1)\n",
    "    ret2 = sess.run(r2)\n",
    "    ret3 = sess.run(r3)\n",
    "    ret4 = sess.run(r4)\n",
    "    ret5 = sess.run(r5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.,  18.],\n",
       "         [  8.,  24.]],\n",
       "\n",
       "        [[ 14.,  30.],\n",
       "         [ 11.,  32.]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.,  inf],\n",
       "         [ inf,  inf]],\n",
       "\n",
       "        [[ inf,  inf],\n",
       "         [ inf,  inf]]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.  ,  18.  ],\n",
       "         [  6.75,  23.  ]],\n",
       "\n",
       "        [[ 13.  ,  30.  ],\n",
       "         [ 11.  ,  32.  ]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.,  18.],\n",
       "         [  3.,  23.]],\n",
       "\n",
       "        [[ 13.,  30.],\n",
       "         [ 11.,  32.]]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.,  18.],\n",
       "         [  4.,  23.]],\n",
       "\n",
       "        [[ 13.,  30.],\n",
       "         [ 11.,  32.]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  6.   ,  18.   ],\n",
       "         [  4.   ,   8.   ]],\n",
       "\n",
       "        [[  4.667,  30.   ],\n",
       "         [ 11.   ,  32.   ]]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.123,  0.992,  0.015,  0.   ],\n",
       "       [-0.246, -0.029, -0.105, -0.963],\n",
       "       [-0.615, -0.065, -0.748,  0.241],\n",
       "       [-0.739, -0.102,  0.656,  0.12 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test pcapool\n",
    "tt1 = np.array([[1,2,5,6],[3,3,7,8],[13,13,13,14],[11,11,11,11]])\n",
    "tt1 = np.reshape(tt1, [4, 4,1])\n",
    "[U, S, V] = np.linalg.svd(np.matmul(tt1, tt1.transpose([0, 2, 1])))\n",
    "U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.124, -11.446],\n",
       "       [-26.514, -22.   ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = U[:, :, 0]\n",
    "U = np.reshape(U, [4, 1, 4])\n",
    "ret1 = np.reshape(np.matmul(U, tt1), [2,2])\n",
    "ret1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.062,   5.723],\n",
       "       [ 13.257,  11.   ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [1, 4, 4, 2])\n",
    "y = pca_pool(extract_patches(x, padding='VALID'), m=1)\n",
    "with tf.Session() as sess:\n",
    "    ret = sess.run(y, feed_dict={x: tt})\n",
    "ret[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.458,  0.623,  0.59 , -0.234],\n",
       "       [-0.434, -0.578,  0.473,  0.503],\n",
       "       [-0.552, -0.401, -0.274, -0.678],\n",
       "       [-0.546,  0.342, -0.594,  0.482]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test pcapool\n",
    "tt1 = np.array([[1,1,5,6],[3,8,8,4],[9,10,13,13],[16,12,15,16]]).transpose()\n",
    "[U, S, V] = np.linalg.svd(np.matmul(tt1, tt1.transpose()))\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.462,  -5.72 , -11.362, -14.77 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = U[:,0]\n",
    "np.matmul(U, tt1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  3.635,  17.987],\n",
       "         [  5.396,  23.246]],\n",
       "\n",
       "        [[ 13.241,  28.776],\n",
       "         [ 10.972,  29.547]]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [1, 4, 4, 2])\n",
    "y = pca_pool(extract_patches(x, 'VALID'), m=2)\n",
    "with tf.Session() as sess:\n",
    "    ret = sess.run(y, feed_dict={x: tt})\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "#     3x3 conv, 32 outputs\n",
    "    'wc0': tf.Variable(tf.random_normal([3, 3, 3, 32])),\n",
    "#     5x5 conv, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "    \n",
    "#     combine of majority and pca with sharing weights 2 * 2 psize\n",
    "    'wc2': tf.Variable(tf.random_normal([1]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc0': tf.Variable(tf.random_normal([32]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input and preprocessing\n",
    "data = data[0:1]\n",
    "data = gcn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, [data.shape[0], hight, width, color_channel])\n",
    "# Net setting 5*5 conv with stride = 1, 2*2 pooling with strides = 2, with valid padding\n",
    "cov1 = conv2d(x, 'VALID', weights['wc1'], biases['bc0'], strides=1)\n",
    "# maxpool\n",
    "Net1_1 = maxpool(cov1, 'VALID', ksize=2, stride=2)\n",
    "\n",
    "# extract patches\n",
    "p = extract_patches(cov1, 'VALID', ksize=2, stride=2)\n",
    "\n",
    "\n",
    "# pcapool with m = 2\n",
    "Net1_2 = pcapool(p, m = 1)\n",
    "\n",
    "# computer frequency tensor\n",
    "f = majority_frequency(p)\n",
    "\n",
    "# weighted before maxpool\n",
    "# p is patches tensor, f is frequncy tensor, the last parameter is the method for compute weight\n",
    "Net1_3 = weight_max(p, f, tf.reduce_max)\n",
    "# maxpool before weighting\n",
    "Net1_4 = max_weight(p, f, tf.reduce_max)\n",
    "\n",
    "\n",
    "# linearly combine votepool and pcapool result (sharing parameters through all patches and all features)\n",
    "Net1_5 = tf.add(tf.multiply(Net1_2, weights['wc2']), \n",
    "                tf.multiply(tf.to_float(votepool(p)), tf.subtract(tf.constant([1.]), weights['wc2'])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Net setting 5*5 conv with stride = 1, 2*2 pooling with strides = 2, with valid padding\n",
    "    Net_result0 = sess.run(cov1, feed_dict={x: data})\n",
    "    Net_result1 = sess.run(Net1_1, feed_dict={x: data})\n",
    "    Net_result2 = sess.run(Net1_2, feed_dict={x: data})\n",
    "    Net_result3 = sess.run(Net1_3, feed_dict={x: data})\n",
    "    Net_result4 = sess.run(Net1_4, feed_dict={x: data})\n",
    "    Net_result5 = sess.run(Net1_5, feed_dict={x: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   1.006,   0.546,\n",
       "          2.948,   1.461,   1.535,   1.213,   1.409,   0.   ,   0.23 ],\n",
       "       [  0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.768,\n",
       "          0.643,   2.887,   1.082,   2.061,   1.421,   0.   ,   0.216],\n",
       "       [  0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   3.372,   3.162,\n",
       "          1.152,   0.   ,   0.381,   1.733,   1.567,   0.   ,   0.   ],\n",
       "       [  0.   ,   0.   ,   0.681,   0.299,   1.497,   0.715,   0.   ,\n",
       "          0.   ,   0.003,   0.   ,   0.002,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "          0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.13 ,   1.747,   0.844,   0.509,   0.   ,   3.245,   5.613,\n",
       "          9.897,   8.836,   8.92 ,   5.901,   0.155,   1.067,   0.032],\n",
       "       [  0.   ,   0.034,   0.   ,   0.   ,   0.   ,   2.522,   1.964,\n",
       "          0.168,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.   ,   0.   ,   0.   ,   0.998,   0.   ,   0.175,   2.084,\n",
       "          6.719,   8.569,   9.069,  10.819,  10.643,   9.278,   6.922],\n",
       "       [  8.534,   8.695,   6.658,   7.688,  10.33 ,  11.241,   7.45 ,\n",
       "          7.808,   5.993,   3.788,   2.707,   1.881,   0.492,   1.194],\n",
       "       [  3.687,   3.11 ,   2.248,   1.36 ,   0.882,   1.334,   0.955,\n",
       "          1.513,   1.754,   2.538,   3.206,   3.279,   3.784,   4.184],\n",
       "       [  3.635,   3.53 ,   3.514,   3.388,   3.004,   2.891,   3.616,\n",
       "          3.626,   3.795,   3.983,   4.018,   4.155,   4.025,   3.772],\n",
       "       [  3.407,   3.454,   2.953,   3.065,   3.588,   3.798,   3.938,\n",
       "          4.201,   4.394,   4.35 ,   4.536,   4.599,   4.401,   4.331],\n",
       "       [  4.421,   3.872,   4.325,   4.632,   3.99 ,   3.879,   4.08 ,\n",
       "          4.029,   4.342,   4.558,   4.699,   4.291,   4.148,   4.03 ],\n",
       "       [  4.717,   4.667,   4.443,   4.414,   3.95 ,   4.382,   4.5  ,\n",
       "          4.593,   4.535,   4.332,   3.919,   4.266,   4.37 ,   3.972]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net_result2[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    f.write('feature map value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result0[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nmaxpooling value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result1[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\npcapooling value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result2[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nweight before maxpool value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result3[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nmaxpool before weight value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result4[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nmajority and pca value: \\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, Net_result5[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
