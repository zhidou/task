{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 300000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    \n",
    "    x = tf.reshape(x, shape=[64, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = func.conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Pooling (down-sampling)\n",
    "    p = func.extract_patches(conv1, 'SAME', 2, 2)\n",
    "    f = func.majority_frequency(p)\n",
    "#     maxpooling\n",
    "    maxpool = func.max_pool(p)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = func.conv2d(maxpool, weights['wc2'], biases['bc2'])\n",
    "#     Pooling (down-sampling)\n",
    "    p = func.extract_patches(conv2, 'SAME', 2, 2)\n",
    "    f = func.majority_frequency(p)\n",
    "#     maxpooling\n",
    "    maxpool = func.max_pool(p)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(maxpool, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    ofc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(ofc1, weights['out']), biases['out'])\n",
    "    return ofc1, fc1, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n",
      "[16, 14, 14, 4, 32]\n",
      "[16, 7, 7, 4, 64]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------define graph------------------------------------\n",
    "# Reshape input picture\n",
    "inputxs = tf.split(tf.reshape(x, shape=[batch_size, 28, 28, 1]), axis=0, num_or_size_splits=int(batch_size/16))\n",
    "grad_k_1 = tf.zeros_like(weights['wc1'])\n",
    "grad_k_2 = tf.zeros_like(weights['wc2'])\n",
    "grad_w_3 = tf.zeros_like(weights['wd1'])\n",
    "grad_w_out = tf.zeros_like(weights['out'])\n",
    "grad_b_1 = tf.zeros_like(biases['bc1'])\n",
    "grad_b_2 = tf.zeros_like(biases['bc2'])\n",
    "grad_b_3 = tf.zeros_like(biases['bd1'])\n",
    "grad_b_out = tf.zeros_like(biases['out'])\n",
    "\n",
    "for inputx in inputxs:\n",
    "    # Convolution Layer\n",
    "    conv1 = func.conv2d(inputx, weights['wc1'], biases['bc1'])\n",
    "    # Pooling (down-sampling)\n",
    "    p1 = func.extract_patches(conv1, 'SAME', 2, 2)\n",
    "    f1 = func.majority_frequency(p1)\n",
    "    #     maxpooling\n",
    "    pool1 = func.max_pool(p1)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = func.conv2d(pool1, weights['wc2'], biases['bc2'])\n",
    "    #     Pooling (down-sampling)\n",
    "    p2 = func.extract_patches(conv2, 'SAME', 2, 2)\n",
    "    f2 = func.majority_frequency(p2)\n",
    "    #     maxpooling\n",
    "    pool2 = func.max_pool(p2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc = tf.reshape(pool2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    ofc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    pred = tf.add(tf.matmul(ofc1, weights['out']), biases['out'])\n",
    "\n",
    "    # ------------------------------define graph------------------------------------\n",
    "\n",
    "    # -----------------------------Define loss and optimizer------------------------\n",
    "    # varList = [weights['wd1'], weights['out'], biases['bd1'], biases['out'], weights['wc2'], biases['bc2'], weights['wc1'], biases['bc1']]\n",
    "    # cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    # opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    # gv = opt.compute_gradients(loss=cost)\n",
    "\n",
    "\n",
    "    # ------------------------------define gradient descent-------------------------\n",
    "\n",
    "    # the last fc\n",
    "    e1 = tf.nn.softmax(pred) - y\n",
    "    grad_w_out += tf.transpose(ofc1) @ e1\n",
    "    grad_b_out += tf.reduce_sum(e1, axis=0)\n",
    "\n",
    "    # the second last fc\n",
    "    # we use droupout at the last second layer, then we should just update the nodes that are active\n",
    "    e2 = tf.multiply(e1 @ tf.transpose(weights['out']), tf.cast(tf.greater(ofc1, 0), dtype=tf.float32)) / dropout\n",
    "    grad_w_3 += tf.transpose(fc) @ e2\n",
    "    grad_b_3 += tf.reduce_sum(e2, axis=0)\n",
    "\n",
    "    # the last pooling layer\n",
    "    e3 = e2 @ tf.transpose(weights['wd1'])\n",
    "    e3 = tf.reshape(e3, pool2.get_shape().as_list())\n",
    "\n",
    "    # the last conv layer\n",
    "    # unpooling get error from pooling layer\n",
    "    e4 = func.error_pooling2conv(e3, p2, pool2, 'max')\n",
    "\n",
    "    # multiply with the derivative of the active function on the conv layer\n",
    "    e4 = tf.multiply(e4, tf.cast(tf.greater(conv2, 0), dtype=tf.float32))\n",
    "    temp1, temp2 = func.filter_gradient(e4, pool1, conv2)\n",
    "    grad_k_2 += temp1\n",
    "    grad_b_2 += temp2\n",
    "\n",
    "    # conv to pool\n",
    "    e5 = func.error_conv2pooling(e4, weights['wc2'])\n",
    "\n",
    "    # pool to the first conv\n",
    "    e6 = func.error_pooling2conv(e5, p1, pool1,'max')\n",
    "    e6 = tf.multiply(e6, tf.cast(tf.greater(conv1, 0), dtype=tf.float32))\n",
    "    temp1, temp2 = func.filter_gradient(e6, inputx, conv1)\n",
    "    grad_k_1 += temp1\n",
    "    grad_b_1 += temp2\n",
    "    \n",
    "    \n",
    "\n",
    "# gradient\n",
    "gv1 = [(grad_k_1 / batch_size, weights['wc1']), (grad_k_2 / batch_size, weights['wc2']), \n",
    "       (grad_w_3 / batch_size, weights['wd1']), (grad_w_out / batch_size, weights['out']),\n",
    "       (grad_b_1 / batch_size, biases['bc1']), (grad_b_2/ batch_size, biases['bc2']), \n",
    "       (grad_b_3 / batch_size, biases['bd1']), (grad_b_out / batch_size, biases['out'])]\n",
    "\n",
    "\n",
    "# apply gradient\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimize = opt.apply_gradients(gv1)\n",
    "\n",
    "# optimizer = opt.apply_gradients(grads_and_vars=gv)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "# Diff1, Diff2, Out = test_conv_net(x, weights, biases, keep_prob)\n",
    "# lost = []\n",
    "# for temp in Out:\n",
    "#     lost.append(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=temp, labels=y)))\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_8:0' shape=(5, 5, 1, 32) dtype=float32_ref>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [16,10] vs. [128,10]\n\t [[Node: sub_7 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Softmax_7, _recv_Placeholder_1_0)]]\n\nCaused by op 'sub_7', defined at:\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-8094718f1f17>\", line 53, in <module>\n    e1 = tf.nn.softmax(pred) - y\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2627, in _sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [16,10] vs. [128,10]\n\t [[Node: sub_7 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Softmax_7, _recv_Placeholder_1_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,10] vs. [128,10]\n\t [[Node: sub_7 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Softmax_7, _recv_Placeholder_1_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-81a20b59d271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,10] vs. [128,10]\n\t [[Node: sub_7 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Softmax_7, _recv_Placeholder_1_0)]]\n\nCaused by op 'sub_7', defined at:\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-8094718f1f17>\", line 53, in <module>\n    e1 = tf.nn.softmax(pred) - y\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2627, in _sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [16,10] vs. [128,10]\n\t [[Node: sub_7 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Softmax_7, _recv_Placeholder_1_0)]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# f = open('output.txt', 'w')\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "#     while step * batch_size < training_iters:\n",
    "    while step < 2:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimize, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            cos, acc = sess.run([cost, accuracy], \n",
    "                                               feed_dict={x: batch_x,\n",
    "                                                          y: batch_y,\n",
    "                                                          keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(cos) + \n",
    "                  \"\\nTraining Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "#     Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:batch_size], y: mnist.test.labels[:batch_size],\n",
    "keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    f.write('conv2 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, pa2[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\npool2 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, po2[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nerror3 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, ee3[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nfirst pool value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, po1[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nerror4 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, ee4[0,:,:,0], delimiter=', ',fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad1[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012207 0.0\n",
      "0.000549316 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00622559 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for g, g1 in zip(grad, grad1):\n",
    "    print(np.max(g[0] - g1[0]) - np.min(g[0] - g1[0]), np.max(g[1] - g1[1]) - np.min(g[1] - g1[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.622,  0.622,\n",
       "        0.622,  0.622,  0.622,  0.622,  0.622,  0.622,  0.622,  0.622,\n",
       "        0.622,  0.622,  0.   ,  0.   ,  0.622,  0.622,  0.622,  0.622,\n",
       "        0.622,  0.622,  0.622,  0.622,  0.622,  0.622,  0.622,  0.622,\n",
       "        0.   ,  0.   ,  0.622,  0.622,  0.622,  2.578,  2.995,  2.898,\n",
       "        2.34 ,  3.241,  2.774,  3.216,  1.88 ,  0.   ,  0.   ,  0.   ,\n",
       "        0.622,  0.622,  0.622,  4.386,  3.872,  3.893,  3.087,  2.465,\n",
       "        2.141,  2.869,  2.074,  0.   ,  0.   ,  0.   ,  0.622,  0.622,\n",
       "        0.622,  2.077,  0.737,  0.031,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.622,  0.622,  0.622,  0.447,\n",
       "        0.   ,  0.   ,  0.   ,  0.75 ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.622,  0.622,  0.622,  0.622,  0.622,  1.976,\n",
       "        4.029,  3.67 ,  0.178,  0.   ,  0.   ,  0.205,  0.   ,  0.   ,\n",
       "        0.622,  0.622,  0.622,  0.622,  2.304,  4.501,  3.834,  0.703,\n",
       "        0.   ,  0.   ,  0.   ,  0.622,  0.   ,  0.   ,  0.622,  0.622,\n",
       "        0.622,  2.027,  4.828,  3.574,  0.698,  0.   ,  0.   ,  0.   ,\n",
       "        0.622,  0.622,  0.   ,  0.   ,  0.622,  0.622,  0.813,  4.458,\n",
       "        3.953,  0.766,  0.   ,  0.   ,  0.   ,  0.622,  0.622,  0.622,\n",
       "        0.   ,  0.   ,  0.622,  0.622,  4.076,  4.693,  1.181,  0.   ,\n",
       "        0.   ,  0.   ,  0.622,  0.622,  0.622,  0.622,  0.   ,  0.   ,\n",
       "        0.622,  0.622,  4.835,  1.674,  0.314,  0.   ,  0.   ,  0.594,\n",
       "        0.622,  0.622,  0.622,  0.622], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc1[0,0,0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 14, 14, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(wo - grad[1][0]) - np.min(wo - grad[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(bo - grad[3][0]) - np.min(bo - grad[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(w3 - grad[0][0]) - np.min(w3 - grad[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.9406967e-08"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(b3 - grad[2][0]) - np.min(b3 - grad[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00045776367"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(k2 - grad[4][0]) - np.min(k2 - grad[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9182129e-05"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(b2 - grad[5][0]) - np.min(b2 - grad[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -315.516,  -274.134,  -110.675,   214.852,   469.886],\n",
       "       [ -139.565,  -354.963,   -14.112,   389.47 ,   461.621],\n",
       "       [ -124.195,  -157.435,   383.971,   661.055,   526.735],\n",
       "       [  419.112,   513.28 ,   890.624,  1040.974,  1066.86 ],\n",
       "       [  804.38 ,   680.623,   922.307,  1160.497,  1113.75 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[6][0][:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -315.516,  -274.134,  -110.675,   214.852,   469.886],\n",
       "       [ -139.565,  -354.963,   -14.112,   389.47 ,   461.621],\n",
       "       [ -124.195,  -157.435,   383.97 ,   661.055,   526.735],\n",
       "       [  419.112,   513.28 ,   890.624,  1040.974,  1066.86 ],\n",
       "       [  804.38 ,   680.623,   922.307,  1160.497,  1113.75 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -208.329,  1371.998,  2677.15 , -1897.6  ,  1936.688,    44.462,\n",
       "        -160.821,   742.401,   621.907,  2912.838,  1529.066,  3433.003,\n",
       "         135.857, -1745.254,  2003.65 ,    17.914,  3355.716,  -864.316,\n",
       "         725.766,   287.84 ,  -320.119,   391.264,  2012.347,  4179.506,\n",
       "        -473.446,  1613.412,   398.612,  3576.725,  3137.878,  2353.416,\n",
       "        2589.489,   423.992], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -208.329,  1372.001,  2677.152, -1897.599,  1936.688,    44.462,\n",
       "        -160.821,   742.401,   621.907,  2912.84 ,  1529.065,  3433.004,\n",
       "         135.857, -1745.253,  2003.649,    17.914,  3355.718,  -864.316,\n",
       "         725.767,   287.84 ,  -320.119,   391.264,  2012.346,  4179.504,\n",
       "        -473.446,  1613.411,   398.612,  3576.727,  3137.877,  2353.414,\n",
       "        2589.489,   423.992], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  10.479,   40.462,  -20.684,  -68.879,  -72.81 ],\n",
       "       [   7.344,    1.926,  -51.897,  -53.197,  -39.338],\n",
       "       [  49.751,   -7.294,   -6.286,  -43.237,  -71.886],\n",
       "       [  -6.139,   14.189,  -37.93 , -101.595,  -38.394],\n",
       "       [ -29.756,  -19.656,  -55.514,  -51.635,    2.628]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -18.696,    9.353,  -38.062,   10.527,  -15.099,  -22.246,\n",
       "        120.452,   56.936,  -12.423,  -74.125,   60.832,   52.296,\n",
       "         46.787,  -70.468,   -1.294,   55.804,   45.347,  -25.526,\n",
       "         59.663,   24.105,    7.68 ,   33.834,  -59.61 ,   34.805,\n",
       "        -28.622,   26.149,  -25.254,  -46.559,   70.685,   54.573,\n",
       "         -9.246,   26.074,   90.612,   34.13 ,  -12.593,   26.451,\n",
       "         44.761,  119.004,   33.882,  -55.635,   -5.529,   11.017,\n",
       "         13.544,   99.017,   82.256,  -29.706,  -50.963,  -51.528,\n",
       "         -6.476,   24.699,  111.793,   48.072,  109.696,   67.398,\n",
       "          3.102,    1.572,  -20.94 ,   20.755,    4.561,   11.462,\n",
       "         69.632,   -2.096,  -36.653,   53.967], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -18.696,    9.353,  -38.062,   10.527,  -15.099,  -22.246,\n",
       "        120.452,   56.936,  -12.423,  -74.125,   60.832,   52.296,\n",
       "         46.787,  -70.468,   -1.294,   55.804,   45.347,  -25.526,\n",
       "         59.663,   24.105,    7.68 ,   33.834,  -59.61 ,   34.805,\n",
       "        -28.622,   26.149,  -25.254,  -46.559,   70.685,   54.573,\n",
       "         -9.246,   26.074,   90.612,   34.13 ,  -12.593,   26.451,\n",
       "         44.761,  119.004,   33.882,  -55.635,   -5.529,   11.017,\n",
       "         13.544,   99.017,   82.256,  -29.706,  -50.963,  -51.528,\n",
       "         -6.476,   24.699,  111.793,   48.072,  109.696,   67.398,\n",
       "          3.102,    1.573,  -20.94 ,   20.755,    4.561,   11.462,\n",
       "         69.632,   -2.096,  -36.653,   53.967], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = np.array([range(1, 65)])\n",
    "tt = np.reshape(tt, [2, 2, 4,4], order='C')\n",
    "tt = np.transpose(tt, [0, 2,3,1])\n",
    "\n",
    "tt[0,0,3,0] = 3\n",
    "tt[0,2,0,0] = 13\n",
    "tt[0,2,1,0] = 13\n",
    "tt[0,2,3,0] = 11\n",
    "tt[0,3,2,0] = 11\n",
    "tt[0,3,3,0] = 11\n",
    "tt[0,0,0,1] = 18\n",
    "tt[0,1,0,1] = 18\n",
    "tt[0,1,1,1] = 18\n",
    "tt[0,0,2,1] = 23\n",
    "tt[0,0,3,1] = 23\n",
    "tt[0,2,0,1] = 30\n",
    "\n",
    "x = tf.constant(tt, dtype=tf.float32)\n",
    "p = func.extract_patches(x, \"VALID\", 2, 2)\n",
    "maxx = func.max_pool(p)\n",
    "maxx = tf.reshape(maxx, [2,2,2,1,2])\n",
    "mark = tf.cast(tf.equal(p, maxx), dtype=tf.float32)\n",
    "mark = tf.multiply(mark, maxx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p = tf.reshape(mark, x.get_shape().as_list())\n",
    "p = func.extract_patches(p, \"VALID\", 2, 2)\n",
    "p = tf.reshape(p, x.get_shape().as_list())\n",
    "\n",
    "\n",
    "# x = tf.reshape(x, [4,4])\n",
    "with tf.Session() as sess:\n",
    "    retx, retp = sess.run([mark, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fk = np.array([\n",
    "    [\n",
    "        [0.8,0.1,-0.6], [0.3,0.5,0.7],[-0.4,0,-0.2]\n",
    "    ],\n",
    "    [\n",
    "        [0.8,0.1,-0.6], [0.3,0.5,0.7],[-0.4,0,-0.2]\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt1 = np.array([\n",
    "    [\n",
    "        [16, 2, 3, 13], [5,11,10,8], [9,7,6,12], [4, 14,15, 1]\n",
    "    ], \n",
    "    [\n",
    "        [16, 2, 3, 13], [5,11,10,8], [9,7,6,12], [4, 14,15, 1]\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt1 = np.array([[[16, 2, 3, 13], [5,11,10,8], [9,7,6,12], [4, 14,15, 1]], [[16, 2, 3, 13], [5,11,10,8], [9,7,6,12], [4, 14,15, 1]]])\n",
    "tt1 = np.array([tt1, np.flip(tt1, axis=1)])\n",
    "tt1 = tt1.transpose([0,2,3,1])\n",
    "fk = np.array([[[0.8,0.1,-0.6], [0.3,0.5,0.7],[-0.4,0,-0.2]]])\n",
    "fk = np.array([fk, np.flip(fk,axis=1)])\n",
    "fk = fk.transpose([0,2,3,1])\n",
    "fk = fk.transpose([1,2,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 14, 15,  1],\n",
       "       [ 9,  7,  6, 12],\n",
       "       [ 5, 11, 10,  8],\n",
       "       [16,  2,  3, 13]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1[1,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8  0.8  0.8  0.8]\n",
      " [ 0.8  0.8  0.8  0.8]\n",
      " [ 0.8  0.8  0.8  0.8]\n",
      " [ 0.8  0.8  0.8  0.8]]\n",
      "[[ 0.6  0.6  0.6  0.6]\n",
      " [ 0.6  0.6  0.6  0.6]\n",
      " [ 0.6  0.6  0.6  0.6]\n",
      " [ 0.6  0.6  0.6  0.6]]\n",
      "[[ 0.4  0.4  0.4  0.4]\n",
      " [ 0.4  0.4  0.4  0.4]\n",
      " [ 0.4  0.4  0.4  0.4]\n",
      " [ 0.4  0.4  0.4  0.4]]\n"
     ]
    }
   ],
   "source": [
    "xw = tf.constant(tt1, dtype=tf.float32)\n",
    "yw = tf.Variable(tf.ones_like(xw))\n",
    "# xw = tf.split(xw, axis=0, num_or_size_splits=2)\n",
    "# for i in xw:\n",
    "zw = tf.add(yw, 1)\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(tf.reduce_sum(tf.subtract(zw, 0)))\n",
    "\n",
    "init1 = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init1)\n",
    "    for i in range(3):\n",
    "        yww, o = sess.run([yw, opt])\n",
    "        print(yww[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]]],\n",
       "\n",
       "\n",
       "       [[[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]],\n",
       "\n",
       "        [[-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001],\n",
       "         [-0.001, -0.001]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_like_8:0' shape=(2, 1, 4, 4, 2) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_8:0' shape=(2, 4, 4, 2) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(retx[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'gradients_5/MatMul_10_grad/tuple/control_dependency_1:0' shape=(3136, 1024) dtype=float32>,\n",
       "  <tf.Variable 'Variable_10:0' shape=(3136, 1024) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/MatMul_11_grad/tuple/control_dependency_1:0' shape=(1024, 10) dtype=float32>,\n",
       "  <tf.Variable 'Variable_11:0' shape=(1024, 10) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/Add_10_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_14:0' shape=(1024,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/Add_11_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_15:0' shape=(10,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/Conv2D_16_grad/tuple/control_dependency_1:0' shape=(5, 5, 32, 64) dtype=float32>,\n",
       "  <tf.Variable 'Variable_9:0' shape=(5, 5, 32, 64) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/BiasAdd_11_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_13:0' shape=(64,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/Conv2D_15_grad/tuple/control_dependency_1:0' shape=(5, 5, 1, 32) dtype=float32>,\n",
       "  <tf.Variable 'Variable_8:0' shape=(5, 5, 1, 32) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_5/BiasAdd_10_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_12:0' shape=(32,) dtype=float32_ref>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.variables.Variable"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gv[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to literal (<ipython-input-60-1f5fa26a16a9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-1f5fa26a16a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2,3 += 3\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to literal\n"
     ]
    }
   ],
   "source": [
    "2,3 += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.],\n",
       "       [  0.,   6.,   0.,   8.],\n",
       "       [  0.,   0.,  11.,  11.],\n",
       "       [  0.,  14.,  11.,  11.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retp[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retx[0,0,0,:,0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
