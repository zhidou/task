{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import functions as func\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 16\n",
    "# mini_batch = 16\n",
    "# train_iter = batch_size//mini_batch\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "para = [weights['wc1'], weights['wc2'], weights['wd1'], weights['out'], biases['bc1'], biases['bc2'], biases['bd1'], biases['out']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------define graph------------------------------------\n",
    "# Reshape input picture\n",
    "inputx = tf.reshape(x, shape=[batch_size, 28, 28, 1])\n",
    "yi = y\n",
    "\n",
    "# ------------------------------The tf defined network--------------------------\n",
    "# conv11 = func.conv2d(inputx, weights['wc1'], biases['bc1'])\n",
    "# pool11 = tf.nn.max_pool(conv11, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "# conv22 = func.conv2d(pool11, weights['wc2'], biases['bc2'])\n",
    "# pool22 = tf.nn.max_pool(conv22, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "# fcc = tf.reshape(pool22, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "# fc11 = tf.add(tf.matmul(fcc, weights['wd1']), biases['bd1'])\n",
    "# fc11 = tf.nn.relu(fc11)\n",
    "\n",
    "# pred1 = tf.add(tf.matmul(fc11, weights['out']), biases['out'])\n",
    "\n",
    "# ------------------------------self defined network-----------------------------\n",
    "# Convolution Layer\n",
    "conv1 = func.conv2d(inputx, weights['wc1'], biases['bc1'])\n",
    "# Pooling (down-sampling)\n",
    "p1 = func.extract_patches(conv1, 'SAME', 2, 2)\n",
    "f1 = func.majority_frequency(p1)\n",
    "#     maxpooling\n",
    "# pool1, mask1 = func.weight_pool_with_mask(p1, f1, pool_fun=func.majority_pool_with_mask, reduce_fun=tf.reduce_max)\n",
    "pool1, mask1 = func.max_pool_with_mask(p1)\n",
    "\n",
    "# Convolution Layer\n",
    "conv2 = func.conv2d(pool1, weights['wc2'], biases['bc2'])\n",
    "#     Pooling (down-sampling)\n",
    "p2 = func.extract_patches(conv2, 'SAME', 2, 2)\n",
    "f2 = func.majority_frequency(p2)\n",
    "#     maxpooling\n",
    "# pool2, mask2 = func.weight_pool_with_mask(p2, f2, pool_fun=func.majority_pool_with_mask, reduce_fun=tf.reduce_max)\n",
    "pool2, mask2 = func.max_pool_with_mask(p2)\n",
    "\n",
    "# Fully connected layer\n",
    "# Reshape conv2 output to fit fully connected layer input\n",
    "fc = tf.reshape(pool2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "fc1 = tf.add(tf.matmul(fc, weights['wd1']), biases['bd1'])\n",
    "fc1 = tf.nn.relu(fc1)\n",
    "# Apply Dropout\n",
    "# fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "# Output, class prediction\n",
    "pred = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "correct_pred = tf.cast(tf.equal(tf.argmax(pred, 1), tf.argmax(yi, 1)), dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------define graph------------------------------------\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "gv = opt.compute_gradients(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)))\n",
    "# ------------------------------define gradient descent-------------------------\n",
    "\n",
    "# the last fc\n",
    "e = tf.nn.softmax(pred) - yi\n",
    "grad_w_out = tf.transpose(fc1) @ e\n",
    "grad_b_out = tf.reduce_sum(e, axis=0)\n",
    "\n",
    "# the second last fc\n",
    "# we use droupout at the last second layer, then we should just update the nodes that are active\n",
    "e = tf.multiply(e @ tf.transpose(weights['out']), tf.cast(tf.greater(fc1, 0), dtype=tf.float32)) #/ dropout\n",
    "grad_w_3 = tf.transpose(fc) @ e\n",
    "grad_b_3 = tf.reduce_sum(e, axis=0)\n",
    "\n",
    "# the last pooling layer\n",
    "e = e @ tf.transpose(weights['wd1'])\n",
    "e = tf.reshape(e, pool2.get_shape().as_list())\n",
    "\n",
    "# the last conv layer\n",
    "# unpooling get error from pooling layer\n",
    "e = func.error_pooling2conv(e, mask2)\n",
    "\n",
    "# multiply with the derivative of the active function on the conv layer\n",
    "#     this one is also important this is a part from the upsampling, but \n",
    "e = tf.multiply(e, tf.cast(tf.greater(conv2, 0), dtype=tf.float32))\n",
    "temp1, temp2 = func.filter_gradient(e, pool1, conv2)\n",
    "grad_k_2 = temp1\n",
    "grad_b_2 = temp2\n",
    "\n",
    "# conv to pool\n",
    "e = func.error_conv2pooling(e, weights['wc2'])\n",
    "\n",
    "# pool to the first conv\n",
    "e = func.error_pooling2conv(e, mask1)\n",
    "e = tf.multiply(e, tf.cast(tf.greater(conv1, 0), dtype=tf.float32))\n",
    "temp1, temp2 = func.filter_gradient(e, inputx, conv1)\n",
    "grad_k_1 = temp1\n",
    "grad_b_1 = temp2\n",
    "    \n",
    "    \n",
    "\n",
    "# gradient\n",
    "gv1 = [(grad_k_1, weights['wc1']), (grad_k_2, weights['wc2']), \n",
    "       (grad_w_3 / batch_size, weights['wd1']), (grad_w_out / batch_size, weights['out']),\n",
    "       (grad_b_1, biases['bc1']), (grad_b_2, biases['bc2']), \n",
    "       (grad_b_3 / batch_size, biases['bd1']), (grad_b_out / batch_size, biases['out'])]\n",
    "optimizer = opt.apply_gradients(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between tf and mine\n",
      "0.115223 0.0\n",
      "0.607223 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.022274 0.0\n",
      "0.000829935 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.113621 0.0\n",
      "0.823597 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0346107 0.0\n",
      "0.00120926 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.115806 0.0\n",
      "0.708008 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0287628 0.0\n",
      "0.00100803 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.108277 0.0\n",
      "0.622374 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0341339 0.0\n",
      "0.00102392 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.10813 0.0\n",
      "0.580852 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0270348 0.0\n",
      "0.000722528 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0888213 0.0\n",
      "0.557357 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0258408 0.0\n",
      "0.000818372 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.100033 0.0\n",
      "0.565414 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0248566 0.0\n",
      "0.000751257 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.117157 0.0\n",
      "0.621402 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0245361 0.0\n",
      "0.00075984 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.104403 0.0\n",
      "0.579503 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0221634 0.0\n",
      "0.000899792 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0999888 0.0\n",
      "0.581717 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0214539 0.0\n",
      "0.000694275 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.102337 0.0\n",
      "0.59862 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0266495 0.0\n",
      "0.000892162 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.109063 0.0\n",
      "0.654214 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.025445 0.0\n",
      "0.000818729 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.112787 0.0\n",
      "0.606562 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.017662 0.0\n",
      "0.000705004 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0901205 0.0\n",
      "0.539511 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0240326 0.0\n",
      "0.000914574 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.101048 0.0\n",
      "0.509849 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0264206 0.0\n",
      "0.000698507 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0953289 0.0\n",
      "0.547255 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0202179 0.0\n",
      "0.000734568 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0994798 0.0\n",
      "0.561208 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0337067 0.0\n",
      "0.000700235 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.108737 0.0\n",
      "0.571893 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0300369 0.0\n",
      "0.000694335 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.100793 0.0\n",
      "0.550229 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0245247 0.0\n",
      "0.000775456 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0912676 0.0\n",
      "0.573152 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0216408 0.0\n",
      "0.000697136 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0996701 0.0\n",
      "0.548122 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0231247 0.0\n",
      "0.000727415 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0967951 0.0\n",
      "0.482642 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0264511 0.0\n",
      "0.000743628 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0871381 0.0\n",
      "0.565911 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0269775 0.0\n",
      "0.000788212 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0985987 0.0\n",
      "0.542008 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.017313 0.0\n",
      "0.000572205 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0809183 0.0\n",
      "0.38256 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0154333 0.0\n",
      "0.000419736 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0868625 0.0\n",
      "0.54377 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0182457 0.0\n",
      "0.000730693 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0964565 0.0\n",
      "0.439857 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0142231 0.0\n",
      "0.000504375 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0869036 0.0\n",
      "0.437581 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0140457 0.0\n",
      "0.000549197 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0655728 0.0\n",
      "0.391266 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0143356 0.0\n",
      "0.000545025 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0694382 0.0\n",
      "0.389765 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0136414 0.0\n",
      "0.000483751 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.083033 0.0\n",
      "0.45488 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0172119 0.0\n",
      "0.000449777 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0800758 0.0\n",
      "0.43282 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0172749 0.0\n",
      "0.000533104 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0788534 0.0\n",
      "0.391595 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0117941 0.0\n",
      "0.00043416 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.07436 0.0\n",
      "0.433442 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0121498 0.0\n",
      "0.000483871 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0826511 0.0\n",
      "0.368663 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0151405 0.0\n",
      "0.000393748 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0852439 0.0\n",
      "0.443786 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0187263 0.0\n",
      "0.000520229 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0593832 0.0\n",
      "0.289285 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00819969 0.0\n",
      "0.000302076 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0718856 0.0\n",
      "0.394949 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0148506 0.0\n",
      "0.000482082 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0816131 0.0\n",
      "0.484273 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0154228 0.0\n",
      "0.000545621 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0780337 0.0\n",
      "0.431739 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0150986 0.0\n",
      "0.000582695 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.065069 0.0\n",
      "0.387356 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00978088 0.0\n",
      "0.000399709 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0737914 0.0\n",
      "0.38754 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0136185 0.0\n",
      "0.000418425 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0729151 0.0\n",
      "0.346706 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0145702 0.0\n",
      "0.000335813 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0455315 0.0\n",
      "0.25805 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00577927 0.0\n",
      "0.00029397 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0802445 0.0\n",
      "0.348434 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0120564 0.0\n",
      "0.000353932 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0552429 0.0\n",
      "0.342018 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00650024 0.0\n",
      "0.000313163 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0888177 0.0\n",
      "0.46774 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0208988 0.0\n",
      "0.000570297 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0708426 0.0\n",
      "0.376383 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0118699 0.0\n",
      "0.000462532 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0583677 0.0\n",
      "0.344792 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00704956 0.0\n",
      "0.000286102 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0748451 0.0\n",
      "0.344311 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0129051 0.0\n",
      "0.000332415 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0693535 0.0\n",
      "0.354298 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0143652 0.0\n",
      "0.00043416 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0582585 0.0\n",
      "0.273207 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0078001 0.0\n",
      "0.000252724 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0689957 0.0\n",
      "0.37667 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.010519 0.0\n",
      "0.000324726 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0584138 0.0\n",
      "0.320843 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00920296 0.0\n",
      "0.000347927 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0430065 0.0\n",
      "0.214073 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00569725 0.0\n",
      "0.000220478 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0634907 0.0\n",
      "0.31374 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00856781 0.0\n",
      "0.000257015 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0466496 0.0\n",
      "0.276533 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00771904 0.0\n",
      "0.000241309 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0436206 0.0\n",
      "0.183431 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00390625 0.0\n",
      "0.00016129 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0542665 0.0\n",
      "0.277897 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.011179 0.0\n",
      "0.000304461 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0535691 0.0\n",
      "0.240907 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00774384 0.0\n",
      "0.000220597 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0516357 0.0\n",
      "0.29313 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.01017 0.0\n",
      "0.000321746 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.051135 0.0\n",
      "0.283581 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00811005 0.0\n",
      "0.000283659 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0658531 0.0\n",
      "0.333103 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00724792 0.0\n",
      "0.000340462 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.085919 0.0\n",
      "0.388118 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.013401 0.0\n",
      "0.000401497 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0249384 0.0\n",
      "0.127538 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00414467 0.0\n",
      "0.000123203 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0395151 0.0\n",
      "0.228277 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00640869 0.0\n",
      "0.000252128 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0608734 0.0\n",
      "0.327167 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00763702 0.0\n",
      "0.000327826 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.072521 0.0\n",
      "0.431714 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0194397 0.0\n",
      "0.000465631 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0703713 0.0\n",
      "0.369222 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0148773 0.0\n",
      "0.000400305 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between tf and mine\n",
      "0.0464619 0.0\n",
      "0.240482 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00841522 0.0\n",
      "0.000219882 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0510942 0.0\n",
      "0.265314 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00457096 0.0\n",
      "0.000299513 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0497759 0.0\n",
      "0.253969 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.008564 0.0\n",
      "0.000236273 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0409185 0.0\n",
      "0.182896 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00501633 0.0\n",
      "0.000150204 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0565843 0.0\n",
      "0.342914 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0141907 0.0\n",
      "0.0004462 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.077767 0.0\n",
      "0.401038 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.01577 0.0\n",
      "0.000438452 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0457592 0.0\n",
      "0.240815 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0078907 0.0\n",
      "0.000231624 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0567477 0.0\n",
      "0.286421 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00849533 0.0\n",
      "0.000302553 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0693002 0.0\n",
      "0.401741 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0143127 0.0\n",
      "0.000501931 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0687331 0.0\n",
      "0.376995 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0148926 0.0\n",
      "0.000462055 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0748456 0.0\n",
      "0.456404 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.017601 0.0\n",
      "0.00054121 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0567391 0.0\n",
      "0.269305 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00940895 0.0\n",
      "0.000297666 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0575104 0.0\n",
      "0.337924 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0077095 0.0\n",
      "0.000397205 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0705341 0.0\n",
      "0.358489 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0140591 0.0\n",
      "0.000339508 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0725192 0.0\n",
      "0.349456 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.01091 0.0\n",
      "0.000371575 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0647048 0.0\n",
      "0.372683 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0138283 0.0\n",
      "0.000452638 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0538349 0.0\n",
      "0.289394 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.010006 0.0\n",
      "0.000309467 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0475521 0.0\n",
      "0.312355 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00820446 0.0\n",
      "0.000326037 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0880092 0.0\n",
      "0.47757 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0196056 0.0\n",
      "0.000595331 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0618641 0.0\n",
      "0.360973 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0129919 0.0\n",
      "0.000361681 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0673705 0.0\n",
      "0.36343 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0115452 0.0\n",
      "0.000413179 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0530504 0.0\n",
      "0.292043 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00696564 0.0\n",
      "0.00030154 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0374711 0.0\n",
      "0.221644 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00760651 0.0\n",
      "0.000255585 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0685636 0.0\n",
      "0.40107 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00999832 0.0\n",
      "0.000530124 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0530371 0.0\n",
      "0.299915 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0111465 0.0\n",
      "0.0003649 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0559204 0.0\n",
      "0.284345 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00888157 0.0\n",
      "0.00025022 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0717552 0.0\n",
      "0.390515 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0161915 0.0\n",
      "0.000514746 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0582917 0.0\n",
      "0.28683 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00759697 0.0\n",
      "0.000253975 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0433801 0.0\n",
      "0.246241 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00535202 0.0\n",
      "0.000258923 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0558197 0.0\n",
      "0.294304 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0113344 0.0\n",
      "0.000312686 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0554619 0.0\n",
      "0.284464 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00961876 0.0\n",
      "0.000255704 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0485922 0.0\n",
      "0.278981 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00827026 0.0\n",
      "0.000318408 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0464146 0.0\n",
      "0.240324 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00852585 0.0\n",
      "0.000222683 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0522788 0.0\n",
      "0.260899 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00775909 0.0\n",
      "0.000260234 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0360261 0.0\n",
      "0.180449 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00537682 0.0\n",
      "0.000162125 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0415092 0.0\n",
      "0.234794 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00579166 0.0\n",
      "0.000258088 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0708907 0.0\n",
      "0.352217 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0128555 0.0\n",
      "0.000374913 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0615252 0.0\n",
      "0.334005 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00841904 0.0\n",
      "0.000312805 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.102614 0.0\n",
      "0.49634 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0192566 0.0\n",
      "0.000682831 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0503268 0.0\n",
      "0.236851 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00573826 0.0\n",
      "0.000229418 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0457439 0.0\n",
      "0.208239 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00788879 0.0\n",
      "0.000217855 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0519879 0.0\n",
      "0.264191 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00821877 0.0\n",
      "0.00032562 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0337416 0.0\n",
      "0.165252 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.00474215 0.0\n",
      "0.000158548 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "difference between tf and mine\n",
      "0.0457714 0.0\n",
      "0.258767 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0083046 0.0\n",
      "0.000247955 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0101adae635e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         ret1 all from tf.  gv1 all from mime, gv2 half half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mret1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         conv, pool, ee4, ee3 = sess.run([conv2, pool2, e4, e3], feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         if step % display_step == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhidou/Software/conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhidou/Software/conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhidou/Software/conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/zhidou/Software/conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhidou/Software/conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# f = open('output.txt', 'w')\n",
    "# Launch the graph \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "#     while step < 2:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "#         ret1 all from tf.  gv1 all from mime, gv2 half half\n",
    "        ret1, ret2, optt = sess.run([gv, gv1, optimizer], feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "#         conv, pool, ee4, ee3 = sess.run([conv2, pool2, e4, e3], feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "#         if step % display_step == 0:\n",
    "#             # Calculate batch loss and accuracy\n",
    "#             acc = sess.run(accuracy,feed_dict={x: batch_x,\n",
    "#                                                           y: batch_y,\n",
    "#                                                           keep_prob: 1.})\n",
    "#             print(\"Iter \" + str(step*batch_size) + \"\\nTraining Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        print('difference between tf and mine')\n",
    "        for i, j in zip(ret1, ret2):\n",
    "            print(np.sum(np.abs(i[0] - j[0])), np.sum(np.abs(i[1] - j[1])))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  236.395,    67.118,   245.784,   362.196,   363.377],\n",
       "       [  158.298,   -35.431,   132.62 ,   360.272,   310.257],\n",
       "       [  864.503,   688.634,   865.075,  1098.375,   780.748],\n",
       "       [ 1570.123,  2003.334,  1882.387,  1476.438,  1155.729],\n",
       "       [ 1494.532,  1964.872,  1653.557,  1356.253,   725.913]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret1[0][0][:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  236.395,    67.118,   245.784,   362.196,   363.377],\n",
       "       [  158.298,   -35.431,   132.619,   360.272,   310.257],\n",
       "       [  864.502,   688.634,   865.075,  1098.375,   780.748],\n",
       "       [ 1570.122,  2003.334,  1882.387,  1476.438,  1155.729],\n",
       "       [ 1494.532,  1964.872,  1653.557,  1356.253,   725.913]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret2[0][0][:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between tf and mine\n",
      "0.060152 0.0\n",
      "0.292672 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0168953 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print('difference between tf and mine')\n",
    "for i, j in zip(ret1, ret2):\n",
    "    print(np.sum(np.abs(i[0] - j[0])), np.sum(np.abs(i[1] - j[1])))\n",
    "# print('difference between tf and half')\n",
    "# for i, k in zip(ret1, ret3):\n",
    "#     print(np.max(i[0] - k[0]), np.sum(np.abs(i[1] - k[1])))\n",
    "# print('difference between mine and half')\n",
    "# for j, k in zip(ret2, ret3):\n",
    "#     print(np.max(j[0] - k[0]), np.sum(np.abs(j[1] - k[1])))\n",
    "# print('difference between tf and tf')\n",
    "# for i, l in zip(ret1, ret4):\n",
    "#     print(np.max(i[0] - l[0]), np.sum(np.abs(i[1] - l[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    f.write('conv2 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, conv[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "    \n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\npool2 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, pool[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nerror4 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, ee4[0,:,:,0], delimiter=', ',fmt=\"%.2f\")\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write('\\nerror3 value\\n')\n",
    "with open('output.txt', 'ab') as f:\n",
    "    np.savetxt(f, ee3[0,:,:,0], delimiter=', ',fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = np.array([range(1, 65)])\n",
    "tt = np.reshape(tt, [2, 2, 4,4], order='C')\n",
    "tt = np.transpose(tt, [0, 2,3,1])\n",
    "\n",
    "tt[0,0,3,0] = 3\n",
    "tt[0,2,0,0] = 13\n",
    "tt[0,2,1,0] = 14\n",
    "tt[0,2,3,0] = 11\n",
    "tt[0,3,2,0] = 11\n",
    "tt[0,3,3,0] = 11\n",
    "tt[0,0,0,1] = 18\n",
    "tt[0,1,0,1] = 18\n",
    "tt[0,1,1,1] = 18\n",
    "tt[0,0,2,1] = 23\n",
    "tt[0,0,3,1] = 23\n",
    "tt[0,2,0,1] = 30\n",
    "\n",
    "x = tf.constant(tt, dtype=tf.float32)\n",
    "p = func.extract_patches(x, \"VALID\", 2, 2)\n",
    "pool1, mask = func.max_pool_with_mask(p=p)\n",
    "pool2 = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "# x = tf.reshape(x, [4,4])\n",
    "with tf.Session() as sess:\n",
    "    retx, retp, retm = sess.run([x, pool1, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   8.],\n",
       "       [ 14.,  11.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retp[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  0. ,  0.5], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retm[0,1,0,:,0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
